# ğŸ“š Chatbot com MemÃ³ria Vetorial

Um chatbot inteligente que utiliza embeddings e busca vetorial para responder perguntas com base em documentos fornecidos.

## ğŸ” Estrutura do Projeto

- `chatbot.py`: Interface principal do chatbot
- `call_llm.py`: Gerenciador de chamadas Ã  LLM (Ollama)
- `pre_processing.py`: Processamento e indexaÃ§Ã£o de documentos
- `Docs/`: Pasta para armazenar documentos (PDFs, TXTs, MDs)

## ğŸ› ï¸ Requisitos

- Python 3.8+
- Ollama instalado e rodando localmente
- Modelo deepseek-r1 baixado no Ollama

## âš™ï¸ InstalaÃ§Ã£o

### Usando Conda

``bash
Criar ambiente
conda create -n chatbot-env python=3.8
conda activate chatbot-env
Instalar dependÃªncias
pip install -r requirements.txt``

### Usando venv

```bash
Criar ambiente
python -m venv venv
Ativar ambiente (Windows)
.\venv\Scripts\activate
Ativar ambiente (Linux/Mac)
source venv/bin/activate
Instalar dependÃªncias
pip install -r requirements.txt```



## ğŸš€ Como Usar

1. Coloque seus documentos na pasta `Docs/`
2. Certifique-se que o Ollama estÃ¡ rodando com o modelo deepseek-r1
3. Execute o chatbot:


```bash
python chatbot.py```  


O sistema irÃ¡:
1. Processar os documentos automaticamente na primeira execuÃ§Ã£o
2. Iniciar uma interface de chat no terminal
3. Responder perguntas com base no conteÃºdo dos documentos

## ğŸ“ Notas

- Suporta documentos em PDF, TXT e MD
- Utiliza embeddings para busca semÃ¢ntica
- MantÃ©m histÃ³rico de conversa para contexto
